[
{
	"uri": "//localhost:1313///greengrass201/intro/",
	"title": "소개",
	"tags": [],
	"description": "",
	"content": "AWS IoT Greengrass ML Workshop 이 워크샵을 통해 AWS Greengrass ML 추론 및 Amazon SageMaker의 개념을 배우고 Amazon SageMaker로 기계 학습 모델을 구축하고, 모델을 Greengrass Core에 배포하고, Lambda 함수를 사용하여 Greengrass Core에서 ML 추론을 실행하는 방법을 실습에서 배울 수 있습니다.이 Workshop은 AWS Cloud9 환경 및 Amazon SageMaker 노트북 인스턴스를 사용하여 수행되도록 설계되었습니다. AWS Greengrass가 Cloud9 인스턴스에서 구성 및 실행됩니다. Workshop 환경은 AWS CloudFormation으로 자동 생성됩니다.Amazon Linux는 Cloud9 및 SageMaker의 운영 체제로 사용되며 표준 사용자는 ec2-user입니다.AWS Cloud9에는 클라우드에서 소프트웨어를 코딩, 빌드, 실행, 테스트, 디버깅 및 릴리스하는 데 사용하는 도구 모음이 포함되어 있습니다. 이러한 도구를 사용하려면 AWS Cloud9 통합 개발 환경 또는 IDE를 사용하십시오. 또한 이 워크샵의 실습에 필요한 브라우저에서 셸 액세스를 제공합니다.CIFAR-10 데이터 세트를 기반으로 한 이미지 분류 모델은 Amazon SageMaker와 함께 훈련 된 후 AWS Greengrass에서 사용되어 에지에서 이미지 분류를 수행합니다. 실제 환경에서는 카메라가 연결된 장치를 사용하는 것이 좋습니다. Greengrass 소프트웨어를 실행하는 EC2 인스턴스에 카메라가 연결되어 있지 않기 때문에 정기적으로 스캔되는 디렉토리에 이미지를 복사하기 만하면 이미지가 발견되면 분류됩니다.\n준비사항  AWS 계정: 자원을 생성할 수 있는 권한이 필요합니다. 브라우저: 최신 버전의 크롬, 파이어폭스를 사용하세요.  관리자 권한이 있는 AWS 계정 노트북 브라우저\nWorkshop Content 이 세션은 엣지(edge)에서 머신 러닝 솔루션을 만드는 것에 관한 것입니다.AWS Greengrass는 연결된 디바이스에서 엣지(edge)에서 안전한 방식으로 로컬 컴퓨팅, 메시징, 데이터 캐싱, 동기화 및 ML 추론 기능을 실행할 수있는 소프트웨어입니다.Amazon SageMaker는 개발자와 데이터 과학자가 모든 규모의 기계 학습 모델을 쉽고 빠르게 구축, 교육 및 배포 할 수 있도록하는 완전히 관리되는 플랫폼입니다.이 workshop을 통하여,\n Amazon SageMaker로 이미지를 분류하기 위해 머신 러닝 모델 교육 Greengrass 그룹 프로비저닝 Amazon SageMaker로 훈련 된 모델을 AWS IoT Greengrass에 다운로드 AWS IoT Greengrass에서 사용할 AWS Lambda 함수 생성 Lambda 함수를 사용하여 Greengrass에서 이미지 분류를 수행하십시오. Lambda 함수는 Greengrass에 배포 된 모델을 로드합니다.  Architecture Introduction into Amazon SageMaker Amazon SageMaker는 완전히 관리되는 머신 러닝 서비스입니다. 데이터 과학자와 개발자는 Amazon SageMaker를 사용하여 기계 학습 모델을 쉽고 빠르게 구축 및 교육 한 후 프로덕션 환경에서 호스팅되는 환경에 직접 배포 할 수 있습니다. 탐색 및 분석을 위해 데이터 소스에 쉽게 액세스 할 수 있도록 통합 Jupyter 저작 노트북 인스턴스를 제공하므로 서버를 관리 할 필요가 없습니다. 또한 분산 환경에서 매우 큰 데이터에 대해 효율적으로 실행되도록 최적화 된 공통 기계 학습 알고리즘을 제공합니다.\nIntroduction to AWS Greengrass AWS Greengrass는 AWS 클라우드 기능을 로컬 디바이스로 확장하여 해당 디바이스가 정보 소스에 더 가까운 데이터를 수집 및 분석하는 동시에 로컬 네트워크에서 서로 안전하게 통신 할 수있는 소프트웨어입니다. 보다 구체적으로, AWS Greengrass를 사용하는 개발자는 클라우드에서 서버리스 코드 (AWS Lambda 함수)를 작성하여 애플리케이션의 로컬 실행을 위해 디바이스에 편리하게 배포 할 수 있습니다.\nGreengrass Group AWS Greengrass 그룹 정의는 AWS Greengrass 핵심 장치 및 이와 통신하는 장치에 대한 설정 모음입니다. 다음 다이어그램은 AWS Greengrass 그룹을 구성하는 객체를 보여줍니다.\nContact Us AWS 서비스에 관한 질문은 AWS Support나 담당 AM을 통해서 문의해 주시고 본 워크샵의 발표자료에 관한 질문 사항은 아래의 email 링크를 통해 문의해 주시면 감사하겠습니다. "
},
{
	"uri": "//localhost:1313///greengrass201/",
	"title": "홈",
	"tags": [],
	"description": "",
	"content": "AWS IoT Greengrass ML Workshop   "
},
{
	"uri": "//localhost:1313///greengrass201/lab0/",
	"title": "Lab 1. Launch AWS Resources with CloudFormation",
	"tags": [],
	"description": "",
	"content": "Launch AWS Resources with CloudFormation 이 워크샵에 필요한 AWS 리소스를 생성하기 위해 CloudFormation 스택을 제공합니다.CloudFormation 스택은 AWS Greengrass를 실행하는 데 사용될 EC2 인스턴스를 다른 리소스 중에서 생성합니다. 또한 SageMaker 노트북 인스턴스가 생성되고 부트 스트랩됩니다.아래 링크 중 하나를 선택하면 스택이 시작될 AWS 콘솔의 CloudFormation 으로 자동 redirection됩니다.CloudFormation 스택은 최소한 다음 리소스를 만듭니다.\n  SageMaker에 필요한 S3 버킷\n  EC2 및 SageMaker 인스턴스에 퍼블릭 서브넷 + 보안 그룹이있는 VPC\n  Greengrass를 실행하고 Lambda 함수를 생성하는 Cloud9 인스턴스\n  Jupyter 노트북에서 모델을 정의하는 SageMaker 노트북 인스턴스. 모델 자체는 AWS SageMaker 서비스를 사용하여 학습됩니다.\n  Cloud9 인스턴스의 인스턴스 프로파일\n  AWS 리소스에 액세스하는 데 필요한 IAM 역할\n  Launch CloudFormation stack in eu-central-1 (Frankfurt)\n  Launch CloudFormation stack in eu-west-1 (Ireland)\n  Launch CloudFormation stack in us-east-1 (N. Virginia)\n  Launch CloudFormation stack in us-west-2 (Oregon)\n  AWS CloudFormation 콘솔의 Quick create stack 페이지로 리디렉션 된 후 다음 단계를 수행하여 스택을 시작하십시오.\n EC2 Instance Type for Cloud9: (Optional) Cloud9 instance type을 선택합니다. 미리 설정된 m4.large을 사용하면 workshop을 실행하는 데에 충분합니다. EC2 Instance Type for Sagemaker: (Optional) SageMaker를 위한 instance type을 선택합니다. 미리 설정된 ml.t2.medium'을 사용하면 workshop을 실행하는 데에 충분합니다. Capabilities 에서 I acknowledge that AWS CloudFormation might create IAM resources.을을 체크합니다. Create stack 버튼을 누르고, stack 생성이 완료될 때까지 기다립니다. 10분 정도 소요됩니다.  CloudFormation 콘솔의 스택에 대한 Output섹션에서 생성 된 리소스에 대한 정보르 찾을 수 있습니다. 언제든지 Output섹션으로 돌아와서 값을 확인할 수 있습니다.\nAccess the SageMaker Notebook Instance 생성하신 GGMLWorkshop스택에서 CloudFormation 콘솔의 스택에 대한 Output섹션을 확인합니다. SageMakerInstance 항목의 링크에서 오른쪽 마우스를 클릭하여 Open link in new tab선택합니다.\nSageMaker instance로 이동됩니다.\nAccess the Cloud9 IDE 생성하신 GGMLWorkshop스택에서 CloudFormation 콘솔의 스택에 대한 Output섹션을 확인합니다. Cloud9IDE 항목의 링크에서 오른쪽 마우스를 클릭하여 Open link in new tab선택합니다.\n하기 화면과 같은 Cloud9 instance로 이동됩니다.\nMake your home folder visible Workshop에서 사용되는 많은 파일이 Cloud9 IDE에 복사되어 있습니다. 기본적으로 홈 폴더의 내용은 표시되지 않습니다. 따라서 이것을 변경해야합니다.\nOpen a Terminal Cloud9 IDE에서 terminal (shell)을 열기 위해서 Tab bar에서 +를 클릭하고 New Terminal을 선택합니다.\nCopying Files from/to the Cloud9 IDE Cloud9 IDE로 직접 또는 S3 버킷을 통해 간접적으로 파일을 업로드 할 수 있습니다. 워크숍 중에 나중에 Greengrass Core의 구성 파일을 Cloud9 인스턴스로 복사해야합니다.\nCloud9 IDE process for later in the workshop Upload a file: In the File menu choose Upload Local Files\u0026hellip; Download a file: Right-click on the filename \u0026gt; Download S3 The CloudFormation stack has created a S3 Bucket for you. You can find the bucket name in the outputs section of the CloudFormation stack. A shell variable named \u0026ldquo;$S3_BUCKET\u0026rdquo; also holds the name of the bucket.\nUse the S3 bucket to copy files to/from your EC2 instance. The AWS S3 console can be used to up/download files to/from the S3 bucket.\nIn a terminal in the Cloud9 IDE you would use the awscli to copy files to/from the bucket.\nExample code to be used later in the workshop copy files from the bucketaws s3 cp s3://$S3_BUCKET/my_object .\ncopy files to the bucketaws s3 cp my_file s3://$S3_BUCKET/my_file\n"
},
{
	"uri": "//localhost:1313///greengrass201/lab1/",
	"title": "Lab 2. Train a Model with Amazon SageMaker",
	"tags": [],
	"description": "",
	"content": "Train a Model with Amazon SageMaker Context "
},
{
	"uri": "//localhost:1313///greengrass201/lab2/",
	"title": "실습2. Greengrass Core device에서 Greengrass core software 실행",
	"tags": [],
	"description": "",
	"content": "실습 소개 Greengrass Core device에 Greengrass core software 설치를 실습합니다. Greengrass Core device는 RaspberryPi 또는 NVIDIA Jetson과 같은 open source h/w를 사용할 수도 있으나, 본 실습에서는 EC2에 Greengrass core software 설치합니다.\n실습1에서 다운로드 받은 인증서와 설정 파일들을 실습0에서 생성한 EC2 instance에 복사합니다.\n먼저, 실습0에서 생성한 EC2 instance의 Public DNS 주소를 롹인합니다. 하기와 같은 형식의 명령을 사용하여 실습1]((/greengrass201/lab0/))에서 다운로드 받은 인증서와 설정 파일들을 EC2에 복사합니다.\nscp -i \u0026lt;pem 파일 경로\u0026gt; * ec2-user@\u0026lt;EC2 instance 의 public DNS 주소\u0026gt;:~ 예제\nscp -i ~/hol-us-east-2.pem * ec2-user@ec2-3-17-147-4.us-east-2.compute.amazonaws.com:~ EC2 instance에 SSH로 접속합니다. 하기와 같은 형식의 명령을 사용합니다.\nssh -i \u0026lt;pem 파일 경로\u0026gt; ec2-user@\u0026lt;EC2 instance 의 public DNS 주소\u0026gt;\r예제\nssh -i \u0026quot;~/hol-us-east-2.pem\u0026quot; ec2-user@ec2-3-17-147-4.us-east-2.compute.amazonaws.com\rATS 앤드포인트에 접근하기 위하여 ATS 루트 CA 인증서를 다운로드합니다.\nsudo wget -O /greengrass/certs/root.ca.pem https://www.amazontrust.com/repository/AmazonRootCA1.pem\r하기 명령을 통해서, /greengrass 폴더에 인증서를 압축 해제합니다.\nsudo tar -xzvf \u0026lt;인증서 및 설정 압축 파일 경로\u0026gt; -C /greengrass\r예제\nsudo tar -xzvf 3dbd8f5324-setup.tar.gz -C /greengrass\rEC2 instance (Greengrass core device)에서 AWS IoT Greengrass를 시작합니다.\ncd /greengrass/ggc/core/\rsudo ./greengrassd start\r하기와 같은 명령으로, greengrass 데몬 실행 여부를 확인할 수 있습니다.\nps aux | grep -E 'greengrass.*daemon'\r출력 결과에 /greengrass/ggc/packages/1.10.0/bin/daemon와 같은 내용이 출력되면, 정상적으로 실행된 것입니다.\nlocal laptop에서 python용 AWS IoT Greengrass 코어 SDK 다운로드 합니다.\ngit clone https://github.com/aws/aws-greengrass-core-sdk-python.git\rgreengrassHelloWorld.py가 포함되어 있는 HelloWorld 폴더에 greengrasssdk를 복사합니다. Lambda 함수 배포 패키지를 생성하려면 greengrassHelloWorld.py 파일과 greengrasssdk 폴더를 hello_world_python_lambda.zip이라는 압축된 .zip 파일로 저장합니다. .py 파일과 SDK 폴더는 디렉터리의 루트에 있어야 합니다.\nsudo zip -r hello_world_python_lambda.zip greengrasssdk greengrassHelloWorld.py\r아래 과정을 따라서, lambda를 생성합니다.\nhttps://docs.aws.amazon.com/ko_kr/greengrass/latest/developerguide/create-lambda.html\n "
},
{
	"uri": "//localhost:1313///greengrass201/lab3/",
	"title": "실습3. 기계 학습 추론 (ML inference)",
	"tags": [],
	"description": "",
	"content": "Amazon EMR은 관리형 Hadoop 프레임워크로서 빠르게 빅데이터 분석을 위한 Hadoop 클러스터 구성을 할 수 있습니다. "
},
{
	"uri": "//localhost:1313///greengrass201/lab4/",
	"title": "실습4. AWS 기반 데이터 웨어하우징 - Amazon Redshift",
	"tags": [],
	"description": "",
	"content": "Redshift 을 위한 IAM Role 설정  AWS Management Console에 로그인 한 뒤 IAM 서비스에 접속합니다. Roles를 클릭하고 Create new role을 클릭합니다. Select type of trusted entity 는 AWS service 를 선택하고 Choose the service that will use this role 은 Redshift를 선택합니다. 마지막으로 Select your use case 는 Redshiftcustomizable을 선택한 후 Next: Permissions 버튼을 클릭합니다.  생성할 Role에는 두 개의 Policy를 Attach 합니다. Filter에 s3 를 입력하고 AmazonS3FullAccess 정책을 체크한 후, 다시 Filter에 Glue를 입력하고 AWSGlueConsoleFullAccess 정책을 체크한 후 Next: Tags를 클릭 후, 다음 Next: Review 버튼을 클릭합니다.  Role name에 redshift_role을 입력하고 Create role을 클릭하여 IAM Role 생성을 완료합니다. 차후 실습에 사용을 위해 Role ARN을 기록합니다. (arn:aws:iam:: 으로 시작)   Amazon Redshift 클러스터 생성 실습을 위하여 Redshift 클러스터를 생성합니다. 클러스터는 샘플 데이터가 있는 us-west-2 (Oregon) 와 동일한 리전에 생성해야 합니다. 또한 Redshift 의 접속을 위하여 보안 그룹 설정을 주의하여 생성 하시기 바랍니다.  AWS Management Console에서 Redshift 서비스에 접속 후 좌측 Clusters 탭을 선택 합니다. Launch cluster 버튼을 클릭하여 클러스터 생성을 시작합니다. Cluster identifier, Database name, Master user name, Master user password, Confirm password를 임의대로 차례로 입력한 뒤 Continue를 클릭합니다. (Database Port는 Default Port인 5439 사용합니다.)  Cluster identifier : redshift Database name : redshift Master user name : admin Password: **** (임의의 Redshift Master용 password 생성)    Node Configuration 부분은 default 옵션으로 진행합니다. Continue를 클릭합니다.  Additional Configuration에서 VPC security groups에는 default를 선택합니다. Available roles에는 이전 단계에 생성한 redshift_role을 선택합니다. Continue를 클릭합니다.  Review한 뒤 Launch cluster를 선택하여 클러스터를 생성합니다. Cluster Status가 available이 되면 다음으로 진행합니다.  Redshift 접속 이 과정에서는 Amazon Redshift 클러스터에 연결합니다. 저희 실습에서는 Redshift에서 기본으로 제공하는 쿼리 작성기인 Query editor를 이용합니다. 본 도구는 임시적으로 사용하는 도구이며, 실제로는 JDBC 연결을 통해 ** 적절한 데이터베이스 관리도구를 이용 **하게 됩니다. Redshift 관리 콘솔에서 Query editor를 실행 합니다.  다음 설정을 구성합니다.  Cluster: redshift Database: redshift Username: admin Password: (이전 단계에서 만든 password 입력) Connect 를 클릭    외부 테이블 생성 이 실습에서는 외부 테이블을 생성합니다. 일반 Redshift 테이블과는 달리 외부 테이블은 Amazon S3에 저장된 데이터를 참조합니다. 먼저 외부 스키마를 정의합니다. 외부 스키마는 외부 데이터 카탈로그에 있는 데이터베이스를 참조하고, 클러스터가 사용자 대신 Amazon S3에 액세스할 수 있도록 권한을 부여하는 IAM 역할 식별자(ARN)를 제공합니다.  ** INSERT-YOUR-REDSHIFT-ROLE **을 실습 2에서 생성한 redshift_role의 ARN값으로 대체하고 Query editor에서 이 명령을 실행합니다.  CREATE EXTERNAL SCHEMA spectrum\rFROM DATA CATALOG\rDATABASE 'spectrumdb'\rIAM_ROLE 'INSERT-YOUR-REDSHIFT-ROLE'\rCREATE EXTERNAL DATABASE IF NOT EXISTS\rQuery editor의 결과는 별도 정보가 표시되지 않고 \u0026ldquo;Statement completed successfully\u0026quot;라는 메시지를 수신하면, 다음 단계로 진행하십시오. 이제 spectrum 스키마에 저장될 외부 테이블을 생성합니다. Query editor에서 이 명령을 실행하여 외부 테이블을 생성합니다.  CREATE EXTERNAL TABLE spectrum.sales(\rsalesid INTEGER,\rlistid INTEGER,\rsellerid INTEGER,\rbuyerid INTEGER,\reventid INTEGER,\rdateid SMALLINT,\rqtysold SMALLINT,\rpricepaid DECIMAL(8,2),\rcommission DECIMAL(8,2),\rsaletime TIMESTAMP\r)\rROW FORMAT DELIMITED\rFIELDS TERMINATED BY '\\t'\rSTORED AS TEXTFILE\rLOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales/'\rTABLE PROPERTIES ('numRows'='172000')\rQuery editor에는 아무런 정보가 표시되지 않습니다. 외부 테이블은 테이블의 목록에 표시되지 않기 때문입니다. 이 문이 Amazon S3에 있는 디렉터리를 가리키는 테이블 정의를 생성했습니다. 디렉터리에는 172,456개의 행이 있는 11MB 텍스트 파일 1개가 포함되어 있습니다. 다음은 파일 콘텐츠 샘플입니다.\n2 4 8117 11498 4337 1983 2 76.00 11.40 2008-06-06 05:00:16\r6 10 24858 24888 3375 2023 2 394.00 59.10 2008-07-16 11:59:24\r7 10 24858 7952 3375 2003 4 788.00 118.20 2008-06-26 00:56:06\r8 10 24858 19715 3375 2017 1 197.00 29.55 2008-07-10 02:12:36\r각 줄에는 수량, 가격 및 판매 날짜와 같은 판매 정보가 있습니다.\nAmazon S3에 저장된 데이터를 쿼리 이 실습에서는 외부 테이블에 대해 쿼리를 실행합니다. 이 쿼리는 Redshift Spectrum을 사용하여 Amazon S3에서 바로 데이터를 처리합니다. 다음 명령을 실행하여 S3에 저장된 행의 수를 쿼리합니다.  SELECT COUNT(*) FROM spectrum.sales\r출력값은 파일에 172,456 개의 레코드가 있음을 보여줍니다.\n다음 명령을 실행하여 외부 테이블에 저장된 데이터 샘플을 확인합니다.  SELECT * FROM spectrum.sales LIMIT 10\rS3에 저장된 탭으로 분리된 데이터가 일반 Redshift 테이블과 정확히 동일하게 표시되는 것을 확인할 수 있습니다. Spectrum은 S3에서 데이터를 읽지만 마치 Redshift가 직접 읽는 것처럼 표시합니다.또한, 쿼리는 합계 계산과 같은 일반 SQL 문을 포함할 수 있습니다. 다음 명령을 실행하여 일의 매출을 계산합니다.\nSELECT SUM(pricepaid)\rFROM spectrum.sales\rWHERE saletime::date = '2008-06-26'\rAmazon Redshift Spectrum은 임시 Amazon Redshift 테이블로 데이터를 로드할 필요 없이 Amazon S3에 저장된 데이터에 직접 쿼리를 실행합니다.또한, S3에 저장된 데이터와 Amazon Redshift에 저장된 데이터를 조인할 수 있습니다. 이를 보여주기 위해 event라는 일반 Redshift 테이블을 생성하고 이 테이블로 데이터를 로드합니다.\n 다음 명령을 실행하여 일반 Redshift 테이블을 생성합니다.event 테이블이 페이지 왼쪽의 테이블 목록에 표시됩니다.  CREATE TABLE event(\reventid INTEGER NOT NULL DISTKEY,\rvenueid SMALLINT NOT NULL,\rcatid SMALLINT NOT NULL,\rdateid SMALLINT NOT NULL SORTKEY,\reventname VARCHAR(200),\rstarttime TIMESTAMP\r)\rINSERT-YOUR-REDSHIFT-ROLE을 이전 단계에서 생성한 redshift_role의 ARN 값을 대체하고 Query editor에서 이 명령을 실행하여 데이터를 events 테이블로 로드합니다. 약 30초 가량의 로딩 시간이 소요됩니다.  COPY event\rFROM 's3://id-redshift-uswest2/tickit/allevents_pipe.txt'\rIAM_ROLE 'INSERT-YOUR-REDSHIFT-ROLE'\rDELIMITER '|'\rTIMEFORMAT 'YYYY-MM-DD HH:MI:SS'\rREGION 'us-west-2'\r다음 명령을 실행하여 event 데이터의 샘플을 확인합니다.  SELECT * FROM event LIMIT 10\r이제 이 새로운 event 테이블의 데이터 (Redshift 저장 데이터)와 외부 sales 테이블의 데이터 (S3 저장데이터)를 조인하는 쿼리를 실행할 수 있습니다.\n다음의 명령을 통해 로컬 event 테이블과 외부 sales 테이블을 조인하여 상위 10개 이벤트의 총 매출을 확인합니다.  SELECT TOP 10\rspectrum.sales.eventid,\rSUM(spectrum.sales.pricepaid)\rFROM spectrum.sales, event\rWHERE spectrum.sales.eventid = event.eventid\rAND spectrum.sales.pricepaid \u0026gt; 30\rGROUP BY spectrum.sales.eventid\rORDER BY 2 DESC\r이 쿼리는 가격이 30 USD 이상의 이벤트 별 (Redshift 저장 데이터) 로 그룹화된 총 매출 (S3 저장 데이터) 을 나열합니다.\n다음의 명령을 실행하여 위의 쿼리에 대한 쿼리 플랜을 확인합니다.이 쿼리 플랜은 Redshift가 해당 쿼리를 어떻게 실행할 지 보여줍니다. Amazon S3에 있는 데이터에 대해 S3 Seq Scan, S3 HashAggregate 및 S3 Query Scan 단계가 실행됩니다.  EXPLAIN\rSELECT TOP 10\rspectrum.sales.eventid,\rSUM(spectrum.sales.pricepaid)\rFROM spectrum.sales, event\rWHERE spectrum.sales.eventid = event.eventid\rAND spectrum.sales.pricepaid \u0026gt; 30\rGROUP BY spectrum.sales.eventid\rORDER BY 2 DESC\r파티션된 데이터 사용 외부 테이블은 디렉터리로 사전에 파티션 될 수 있으며, 각 디렉터리는 데이터 하위집합을 포함합니다.데이터를 파티션할 때 파티션 키를 필터링하여 Redshift Spectrum이 스캔하는 데이터의 양을 제한할 수 있습니다.시간에 따라 데이터를 파티션하는 것이 일반적입니다. 예를 들어, 년, 월, 일 및 시간에 따라 파티션할 수 있습니다. 데이터가 여러 소스에서 수신되는 경우, 데이터 소스 식별자와 날짜로 파티션할 수 있습니다.다음은 분할된 데이터를 보여주는 디렉터리 목록으로, 디렉터리에 월별로 파티션된 S3 파일 집합을 표시합니다. (참고: AWS Cli가 설치된 로컬 머신에서 확인 가능 합니다.)\n$ aws s3 ls s3://id-redshift-uswest2/tickit/spectrum/sales_partition/\rPRE saledate=2008-01/\rPRE saledate=2008-02/\rPRE saledate=2008-03/\rPRE saledate=2008-04/\rPRE saledate=2008-05/\rPRE saledate=2008-06/\rPRE saledate=2008-07/\rPRE saledate=2008-08/\rPRE saledate=2008-09/\rPRE saledate=2008-10/\rPRE saledate=2008-11/\r이제 이 데이터를 사용하는 외부 테이블을 정의 합니다.다음 명령을 실행하여 파티션된 데이터에 따라 새로운 sales_partitioned 테이블을 정의합니다.\nCREATE EXTERNAL TABLE spectrum.sales_partitioned(\rsalesid INTEGER,\rlistid INTEGER,\rsellerid INTEGER,\rbuyerid INTEGER,\reventid INTEGER,\rdateid SMALLINT,\rqtysold SMALLINT,\rpricepaid DECIMAL(8,2),\rcommission DECIMAL(8,2),\rsaletime TIMESTAMP\r)\rPARTITIONED BY (saledate DATE)\rROW FORMAT DELIMITED\rFIELDS TERMINATED BY '|'\rSTORED AS TEXTFILE\rLOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/'\rTABLE PROPERTIES ('numRows'='172000')\r(이 쿼리를 실행하면 화면에 응답이 표시되지 않지만, 테이블 정의가 생성됩니다.)salesdate 필드에 따라 테이블이 파티션됨을 Redshift Spectrum에 알려주는 문이 추가되었습니다.그런 다음 Redshift Spectrum은 기존 파티션에 대한 정보를 받아야 어떤 디렉터리를 사용할 지 알 수 있습니다.다음 명령을 실행하여 파티션을 추가합니다.\nALTER TABLE spectrum.sales_partitioned ADD PARTITION (saledate='2008-01-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-01/'\rPARTITION (saledate='2008-02-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-02/'\rPARTITION (saledate='2008-03-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-03/'\rPARTITION (saledate='2008-04-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-04/'\rPARTITION (saledate='2008-05-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-05/'\rPARTITION (saledate='2008-06-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-06/'\rPARTITION (saledate='2008-07-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-07/'\rPARTITION (saledate='2008-08-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-08/'\rPARTITION (saledate='2008-09-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-09/'\rPARTITION (saledate='2008-10-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-10/'\rPARTITION (saledate='2008-11-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-11/'\rPARTITION (saledate='2008-12-01') LOCATION 's3://id-redshift-uswest2/tickit/spectrum/sales_partition/saledate=2008-12/'\r이제 특정 salesdate를 사용하는 모든 쿼리에서 해당 날짜와 관련된 디렉터리만 스캔합니다.비교를 위해 2개의 서로 다른 데이터 소스에 쿼리를 실행합니다. 원래 sales 테이블에 다음 명령을 실행하고 실행에 걸리는 시간을 기록합니다.   SELECT TOP 10\rspectrum.sales.eventid,\rSUM(pricepaid)\rFROM spectrum.sales, event\rWHERE spectrum.sales.eventid = event.eventid\rAND pricepaid \u0026gt; 30\rAND date_trunc('month', saletime) = '2008-12-01'\rGROUP BY spectrum.sales.eventid\rORDER BY 2 DESC\r파티션된 데이터에 다음의 명령을 실행하고 실행에 걸리는 시간을 기록합니다.   SELECT TOP 10\rspectrum.sales_partitioned.eventid,\rSUM(pricepaid)\rFROM spectrum.sales_partitioned, event\rWHERE spectrum.sales_partitioned.eventid = event.eventid\rAND pricepaid \u0026gt; 30\rAND saledate = '2008-12-01'\rGROUP BY spectrum.sales_partitioned.eventid\rORDER BY 2 DESC\r두번째 쿼리가 더 빠르게 실행되는 것을 확인합니다. 이는 Amazon S3에서 읽는 데이터가 더 적기 때문입니다. 데이터 볼륨이 클수록 실행 속도의 차이가 더 분명해 집니다. (다만 본 예제와 같이 데이터량이 작은 경우 그 차이는 미비합니다.) 또한, Amazon S3에서 읽는 데이터량에 따라 Redshift Spectrum에 대한 요금이 부과되므로, 쿼리 실행 비용도 줄어듭니다.파티션에 대한 정보는 SVV_EXTERNAL_PARTITIONS 시스템 뷰에서 확인할 수 있습니다. 다음의 명령을 실행하여 sales_partitioned 테이블에 대한 파티션을 확인합니다.  SELECT *\rFROM SVV_EXTERNAL_PARTITIONS\rWHERE tablename = 'sales_partitioned'\r실습 완료 이번 실습을 완료하였습니다. 비용 발생을 최소화 하기 위하여 실습환경을 정리하십시오.\n "
},
{
	"uri": "//localhost:1313///greengrass201/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313///greengrass201/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313///greengrass201/credits/",
	"title": "크레딧",
	"tags": [],
	"description": "",
	"content": "컨텐츠 최초제작  AWS Philipp Sacha  한글 번역  이세현(Albert Lee)  "
}]